{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "734e3959-de94-4dd4-9091-97ee75ffdd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    to_timestamp,\n",
    "    when,\n",
    "    sum as spark_sum,\n",
    "    lag,\n",
    "    unix_timestamp,\n",
    "    col,\n",
    "    monotonically_increasing_id,\n",
    "    udf\n",
    ")\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import logging\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import (\n",
    "    Distance,\n",
    "    VectorParams,\n",
    "    PointStruct\n",
    ")\n",
    "\n",
    "from fastembed import TextEmbedding\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d5105a2-de4b-4cbc-9b43-4276f9c9918a",
   "metadata": {},
   "outputs": [],
   "source": [
    " spark = SparkSession.builder.appName(\"test qdrant \").config(\"spark.driver.memory\", \"8g\").config(\"spark.executor.memory\", \"8g\").getOrCreate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e51bc5c3-d416-4864-84b7-0d629de1e731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_time: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- category_id: string (nullable = true)\n",
      " |-- category_code: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- user_session: string (nullable = true)\n",
      "\n",
      "+------------------------+----------+----------+-------------------+-------------------------+------+------+---------+------------------------------------+\n",
      "|event_time              |event_type|product_id|category_id        |category_code            |brand |price |user_id  |user_session                        |\n",
      "+------------------------+----------+----------+-------------------+-------------------------+------+------+---------+------------------------------------+\n",
      "|2019-11-01T00:00:00.000Z|view      |1003461   |2053013555631882655|electronics.smartphone   |xiaomi|489.07|520088904|4d3b30da-a5e4-49df-b1a8-ba5943f1dd33|\n",
      "|2019-11-01T00:00:00.000Z|view      |5000088   |2053013566100866035|appliances.sewing_machine|janome|293.65|530496790|8e5f4f83-366c-4f70-860e-ca7417414283|\n",
      "|2019-11-01T00:00:01.000Z|view      |3601530   |2053013563810775923|appliances.kitchen.washer|lg    |712.87|518085591|3bfb58cd-7892-48cc-8020-2f17e6de6e7f|\n",
      "|2019-11-01T00:00:01.000Z|view      |1004775   |2053013555631882655|electronics.smartphone   |xiaomi|183.27|558856683|313628f1-68b8-460d-84f6-cec7a8796ef2|\n",
      "|2019-11-01T00:00:01.000Z|view      |1306894   |2053013558920217191|computers.notebook       |hp    |360.09|520772685|816a59f3-f5ae-4ccd-9b23-82aa8c23d33c|\n",
      "+------------------------+----------+----------+-------------------+-------------------------+------+------+---------+------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV into a DataFrame\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/test.csv\")\n",
    "\n",
    "# Display the first 2 rows\n",
    "# Show schema\n",
    "df.printSchema()\n",
    "\n",
    "# Show sample data\n",
    "df.show(5, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8616c533-a911-4dc9-8369-f1859519be20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Feature engineering completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+\n",
      "|  user_id|product_id|               score|\n",
      "+---------+----------+--------------------+\n",
      "|541999338|   1004873| 0.11002694380292534|\n",
      "|513186499|   3700937|0.010434749505101263|\n",
      "|512436136|   1004544| 0.06195899033158134|\n",
      "|514439576|   1003310|                 1.0|\n",
      "|554155613|   1005115|  0.0663168415792104|\n",
      "|566401872|   1004767|  0.6991228070175439|\n",
      "|556719801|   1307464| 0.05039044969033301|\n",
      "|554683103|  14700087| 0.13874755381604698|\n",
      "|544405527|   1480429|              0.1625|\n",
      "|538524222|   1002532|  0.1473709557915535|\n",
      "+---------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Repartition for parallelism\n",
    "df = df.repartition(200)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 4. Convert `event_time` to Timestamp\n",
    "# ------------------------------------------------------------------------\n",
    "df = df.withColumn(\n",
    "    \"event_time\",\n",
    "    to_timestamp(\"event_time\", \"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\")\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 5. Generate flags for event types\n",
    "# ------------------------------------------------------------------------\n",
    "df = (\n",
    "    df.withColumn(\"view_count\", when(col(\"event_type\") == \"view\", 1).otherwise(0))\n",
    "      .withColumn(\"cart_count\", when(col(\"event_type\") == \"cart\", 1).otherwise(0))\n",
    "      .withColumn(\"purchase_count\", when(col(\"event_type\") == \"purchase\", 1).otherwise(0))\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 6. Compute session-level totals\n",
    "# ------------------------------------------------------------------------\n",
    "df_totals = df.groupBy(\"user_session\").agg(\n",
    "    spark_sum(\"view_count\").alias(\"total_views\"),\n",
    "    spark_sum(\"cart_count\").alias(\"total_carts\"),\n",
    "    spark_sum(\"purchase_count\").alias(\"total_purchases\")\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 7. Compute product-level features (views, carts, purchases) and join\n",
    "# ------------------------------------------------------------------------\n",
    "df_product = df.groupBy(\"user_session\", \"product_id\", \"user_id\").agg(\n",
    "    spark_sum(\"view_count\").alias(\"product_views\"),\n",
    "    spark_sum(\"cart_count\").alias(\"product_carts\"),\n",
    "    spark_sum(\"purchase_count\").alias(\"product_purchases\")\n",
    ")\n",
    "\n",
    "df_features = df_product.join(df_totals, on=\"user_session\", how=\"left\")\n",
    "\n",
    "df_features = (\n",
    "    df_features\n",
    "    .withColumn(\n",
    "        \"F1\",\n",
    "        when(col(\"total_views\") != 0, col(\"product_views\") / col(\"total_views\")).otherwise(0)\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"F2\",\n",
    "        when(col(\"total_carts\") != 0, col(\"product_carts\") / col(\"total_carts\")).otherwise(0)\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"F3\",\n",
    "        when(col(\"total_purchases\") != 0, col(\"product_purchases\") / col(\"total_purchases\")).otherwise(0)\n",
    "    )\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 8. Create window for time-based features\n",
    "# ------------------------------------------------------------------------\n",
    "window_order = Window.partitionBy(\"user_session\").orderBy(\"event_time\")\n",
    "\n",
    "df_time = (\n",
    "    df.withColumn(\"prev_event_time\", lag(\"event_time\").over(window_order))\n",
    "      .withColumn(\n",
    "          \"time_spent_seconds\",\n",
    "          unix_timestamp(\"event_time\") - unix_timestamp(\"prev_event_time\")\n",
    "      )\n",
    "      .na.fill(0, subset=[\"time_spent_seconds\"])\n",
    "      .withColumn(\"time_spent\", col(\"time_spent_seconds\").cast(\"double\"))\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 9. Aggregate time spent per product vs. total\n",
    "# ------------------------------------------------------------------------\n",
    "df_time_agg = df_time.groupBy(\"user_session\", \"product_id\", \"user_id\").agg(\n",
    "    spark_sum(\"time_spent\").alias(\"product_time_spent\")\n",
    ")\n",
    "\n",
    "df_total_time = df_time.groupBy(\"user_session\").agg(\n",
    "    spark_sum(\"time_spent\").alias(\"total_time_spent\")\n",
    ")\n",
    "\n",
    "df_features = (\n",
    "    df_features\n",
    "    .join(df_time_agg, on=[\"user_session\", \"product_id\", \"user_id\"], how=\"left\")\n",
    "    .join(df_total_time, on=\"user_session\", how=\"left\")\n",
    ")\n",
    "\n",
    "df_features = df_features.withColumn(\n",
    "    \"F4\",\n",
    "    when(col(\"total_time_spent\") != 0, col(\"product_time_spent\") / col(\"total_time_spent\"))\n",
    "    .otherwise(0)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 10. Define weights and compute a final score\n",
    "# ------------------------------------------------------------------------\n",
    "w1, w2, w3, w4 = 0.1, 0.25, 0.45, 0.2\n",
    "df_features = (\n",
    "    df_features\n",
    "    .withColumn(\n",
    "        \"score\",\n",
    "        w1 * col(\"F1\") + w2 * col(\"F2\") + w3 * col(\"F3\") + w4 * col(\"F4\")\n",
    "    )\n",
    "    .fillna({\"score\": 0})\n",
    ")\n",
    "\n",
    "final_df = df_features.select(\"user_id\", \"product_id\", \"score\")\n",
    "logger.info(\"Feature engineering completed.\")\n",
    "final_df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cd5896b-0c75-4680-8b5b-3c7065b71940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+\n",
      "|  user_id|product_id|               score|\n",
      "+---------+----------+--------------------+\n",
      "|512528032|  28713076|                 0.1|\n",
      "|541999338|   1004873| 0.11002694380292534|\n",
      "|544768462|  28721761| 0.17487179487179488|\n",
      "|553464787|  22400054|0.006706955629129499|\n",
      "|546526292|  28720354| 0.06014492753623188|\n",
      "|513186499|   3700937|0.010434749505101263|\n",
      "|512436136|   1004544| 0.06195899033158134|\n",
      "|514439576|   1003310|                 1.0|\n",
      "|566492425|   1004209|                 0.1|\n",
      "|554155613|   1005115|  0.0663168415792104|\n",
      "|547136026|   2702050|0.018813650169733784|\n",
      "|566401872|   1004767|  0.6991228070175439|\n",
      "|556719801|   1307464| 0.05039044969033301|\n",
      "|554683103|  14700087| 0.13874755381604698|\n",
      "|516453968|  21401294| 0.03378361475922452|\n",
      "|544405527|   1480429|              0.1625|\n",
      "|538524222|   1002532|  0.1473709557915535|\n",
      "|565881130|   1004258| 0.30000000000000004|\n",
      "|525147147|   5100798|0.030862282878411914|\n",
      "|514095583|   1003475| 0.30000000000000004|\n",
      "+---------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = final_df\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98331a33-f777-4659-b6b4-52c0f3c234e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|user_id  |product_id|score               |user_embedding                                                                                                                                                                                                   |\n",
      "+---------+----------+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|512528032|28713076  |0.1                 |[0.276232074201107,0.08841599933803082,-0.0867210416123271,0.05571263059973717,-0.1584443863015622,-0.04036403875797987,0.037465765886008744,-0.26435832381248475,-0.2843976907432079,-0.13824446242069827]      |\n",
      "|541999338|1004873   |0.11002694380292534 |[0.2911576502025128,0.005667480826377869,-0.05867896229028702,0.045084874145686626,-0.10405522016808391,-0.027522694319486618,-0.0040790855884552,-0.2767762638628483,-0.2775685049593449,-0.12482566135004164]  |\n",
      "|544768462|28721761  |0.17487179487179488 |[0.26518780533224345,0.06306521892547608,-0.20829672291874887,0.01520469430834055,-0.16999196433462205,-0.03015897423028946,0.031612494681030515,-0.2704530455172062,-0.23575519770383835,-0.11621394963003695]  |\n",
      "|553464787|22400054  |0.006706955629129499|[0.27602996239438654,0.062131721153855325,-0.15735190585255623,0.013060641661286355,-0.16700962549075485,-0.07619018331170083,-0.03529330785386264,-0.23802577555179597,-0.2618136487901211,-0.12937247287482023]|\n",
      "|546526292|28720354  |0.06014492753623188 |[0.23902358729392292,0.11279505640268327,-0.23263994157314302,0.014422122947871686,-0.17449348350055516,-0.045854453742504124,0.032711084280163054,-0.2459544837474823,-0.23827031701803209,-0.17217335989698768]|\n",
      "|513186499|3700937   |0.010434749505101263|[0.2682007708586753,0.07271961979568005,-0.10454741790890694,0.03466697614639998,-0.15700254319235685,-0.0023483484983444214,0.011022095428779723,-0.32049056068062787,-0.22833176627755167,-0.14068430261686446]|\n",
      "|512436136|1004544   |0.06195899033158134 |[0.25037884805351496,0.15364983156323433,-0.19443304464221,-0.011605309881269933,-0.22288792110048236,0.0015196792781352999,0.07816427806392312,-0.3405326135456562,-0.1775470405817032,-0.11849435018375516]    |\n",
      "|514439576|1003310   |1.0                 |[0.262751376722008,0.09612045474350453,-0.17127451673150063,0.0013261895626783373,-0.18544207680970431,-0.05161937102675438,0.0016054913867264986,-0.2682224124670029,-0.24028909504413606,-0.14721740079112353] |\n",
      "|566492425|1004209   |0.1                 |[0.24152142424136402,0.1062539041042328,-0.24696727469563484,0.0033758614212274552,-0.18680203361436726,-0.052967946976423264,0.03661713460460305,-0.24527854025363924,-0.23389765471220017,-0.16463500801473857]|\n",
      "|554155613|1005115   |0.0663168415792104  |[0.2282792286016047,0.22587432377040387,-0.21902002915740015,-0.03008053991943598,-0.2767291679978371,-0.09944305792450905,0.003841744409874082,-0.2562093064188957,-0.21819448545575143,-0.20383308902382852]   |\n",
      "|547136026|2702050   |0.018813650169733784|[0.25994658265262843,0.07914098240435125,-0.18884630780667067,0.02130895908921957,-0.20226033474318683,-0.020226466469466686,0.026171612646430732,-0.30888711586594586,-0.19176549986004832,-0.1253244178253226] |\n",
      "|566401872|1004767   |0.6991228070175439  |[0.2612352887168527,0.06442454010248184,-0.16626559104770422,0.044453130476176744,-0.1884259479586035,-0.0182411452755332,0.0030883370898664,-0.3058587528765202,-0.20516164228320122,-0.13538177077425645]      |\n",
      "|556719801|1307464   |0.05039044969033301 |[0.26008756617084144,0.08276333361864091,-0.10666266810148956,0.0537187971174717,-0.19004167364910246,-0.03771622087806464,-0.05000194176100195,-0.3005997568368912,-0.22309168204665186,-0.17644257488427684]   |\n",
      "|554683103|14700087  |0.13874755381604698 |[0.2671545551158488,0.08995250761508942,-0.15825692098587751,0.01441024672240019,-0.21866761473938823,-0.07082608547061682,0.021177475014701488,-0.2752992868423462,-0.220310153067112,-0.12869670217623935]     |\n",
      "|516453968|21401294  |0.03378361475922452 |[0.24440067280083896,0.1144567470997572,-0.2043533615767956,0.003960002772510052,-0.21091555086895825,-0.058633973449468614,-0.002804925944656134,-0.27795456647872924,-0.2020627684891224,-0.16271473737433553] |\n",
      "|544405527|1480429   |0.1625              |[0.27268972471356395,0.07546431422233582,-0.17247644942253829,0.01809267941862345,-0.1891648783814162,-0.09759723227471113,0.010421052388846875,-0.20562727674841882,-0.29741169810295104,-0.1529534326749854]   |\n",
      "|538524222|1002532   |0.1473709557915535  |[0.2776867538690567,0.09359783045947552,-0.11442484036087991,0.037510455958545214,-0.12770185256376862,-0.04516837447881699,0.06208387315273285,-0.22962855994701387,-0.319363908469677,-0.1266149931587279]     |\n",
      "|565881130|1004258   |0.30000000000000004 |[0.26261039087548854,0.10588580258190633,-0.1095387740060687,0.0434975378215313,-0.2157571515068412,-0.04867108967155218,-0.009329366823658347,-0.30475848615169526,-0.2164287991821766,-0.15103107191389428]    |\n",
      "|525147147|5100798   |0.030862282878411914|[0.27593483924865725,0.12085289880633354,-0.09605176523327828,0.02421788387000561,-0.16588229103945196,-0.0148040771484375,0.005406886339187622,-0.2914520561695099,-0.278808830678463,-0.1429291782900691]      |\n",
      "|514095583|1003475   |0.30000000000000004 |[0.26812799647450447,0.08150678984820843,-0.12173931133002043,0.031984368525445464,-0.1958474266342819,-0.09656032454222441,-0.02003162819892168,-0.23594431504607202,-0.2694944553077221,-0.16960780968656763]  |\n",
      "+---------+----------+--------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.sql.functions import split, col\n",
    "\n",
    "\n",
    "\n",
    "# Chuyển đổi user_id thành chuỗi và đóng gói trong một danh sách (Word2Vec yêu cầu input là danh sách từ)\n",
    "df_string = df.withColumn(\"user_id_str\", col(\"user_id\").cast(\"string\"))\n",
    "df_words = df_string.withColumn(\"user_id_list\", split(col(\"user_id_str\"), \"\"))  # Mỗi ký tự là một \"word\"\n",
    "\n",
    "# Áp dụng Word2Vec\n",
    "word2Vec = Word2Vec(vectorSize=10, minCount=0, inputCol=\"user_id_list\", outputCol=\"user_embedding\")\n",
    "model = word2Vec.fit(df_words)\n",
    "df_with_embedding = model.transform(df_words)\n",
    "\n",
    "# Chọn các cột cần thiết\n",
    "df_final = df_with_embedding.select(\"user_id\", \"product_id\", \"score\", \"user_embedding\")\n",
    "\n",
    "# Hiển thị DataFrame với embedding\n",
    "df_final.show(truncate=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0628a89b-7dad-4174-8314-fcac9ec8a7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "INFO:httpx:HTTP Request: GET http://qdrant:6333/collections \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'user_embeddings' đã tồn tại.\n"
     ]
    }
   ],
   "source": [
    "client = QdrantClient(host='qdrant', port=6333)\n",
    "df_pandas = df_final.select(\"user_id\", \"product_id\", \"score\", \"user_embedding\").toPandas()\n",
    "collection_name = \"user_embeddings\"\n",
    "\n",
    "# Kiểm tra xem collection đã tồn tại chưa\n",
    "collections = client.get_collections()\n",
    "if collection_name not in [collection.name for collection in collections.collections]:\n",
    "    client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=10, distance=Distance.COSINE)  # Thay `size` theo kích thước embedding của bạn\n",
    "    )\n",
    "    print(f\"Collection '{collection_name}' đã được tạo.\")\n",
    "else:\n",
    "    print(f\"Collection '{collection_name}' đã tồn tại.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6615215-8316-4c93-97f2-26a76a3a27a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://qdrant:6333/collections \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết nối thành công! Các collections hiện có: collections=[CollectionDescription(name='midjourney'), CollectionDescription(name='user_embeddings')]\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "try:\n",
    "    client = QdrantClient(host='qdrant', port=6333)\n",
    "    collections = client.get_collections()\n",
    "    print(\"Kết nối thành công! Các collections hiện có:\", collections)\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi kết nối đến Qdrant: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "793a2559-0daf-4c33-a3fe-d8ed8bcd9541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.clientserver:Closing down clientserver connection\n"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 20\u001b[0m\n\u001b[1;32m     14\u001b[0m sc \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39mgetOrCreate()\n\u001b[1;32m     15\u001b[0m qdrant_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhost\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqdrant\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Thay thế bằng host thực tế\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mport\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m6333\u001b[39m,           \u001b[38;5;66;03m# Thay thế bằng cổng thực tế nếu khác\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Thêm các thông tin cấu hình khác nếu cần, như API key\u001b[39;00m\n\u001b[1;32m     19\u001b[0m }\n\u001b[0;32m---> 20\u001b[0m broadcast_qdrant_config \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqdrant_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Tên collection trong Qdrant\u001b[39;00m\n\u001b[1;32m     23\u001b[0m collection_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Thay thế bằng tên collection của bạn\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/context.py:1193\u001b[0m, in \u001b[0;36mSparkContext.broadcast\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbroadcast\u001b[39m(\u001b[38;5;28mself\u001b[39m, value: T) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBroadcast[T]\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;124;03m    Broadcast a read-only variable to the cluster, returning a :class:`Broadcast`\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;124;03m    object for reading it in distributed functions. The variable will\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03m    be sent to each cluster only once.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBroadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pickled_broadcast_vars\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/broadcast.py:120\u001b[0m, in \u001b[0;36mBroadcast.__init__\u001b[0;34m(self, sc, value, pickle_registry, path, sock_file)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparkContext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sc\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_broadcast \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241m.\u001b[39msetupBroadcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path)\n\u001b[1;32m    121\u001b[0m broadcast_out: Union[ChunkedStream, IO[\u001b[38;5;28mbytes\u001b[39m]]\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_encryption_enabled:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;66;03m# with encryption, we ask the jvm to do the encryption for us, we send it data\u001b[39;00m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m# over a socket\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1709\u001b[0m, in \u001b[0;36mJVMView.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m UserHelpAutoCompletion\u001b[38;5;241m.\u001b[39mKEY:\n\u001b[1;32m   1707\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m UserHelpAutoCompletion()\n\u001b[0;32m-> 1709\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREFLECTION_COMMAND_NAME\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEND_COMMAND_PART\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer \u001b[38;5;241m==\u001b[39m proto\u001b[38;5;241m.\u001b[39mSUCCESS_PACKAGE:\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m JavaPackage(name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gateway_client, jvm_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, regexp_replace, udf\n",
    "from pyspark.sql.types import IntegerType, ArrayType, FloatType\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct\n",
    "import logging\n",
    "import time\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Cấu hình logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Broadcast configuration để chia sẻ thông tin cấu hình đến các worker nodes\n",
    "sc = SparkContext.getOrCreate()\n",
    "qdrant_config = {\n",
    "    'host': 'qdrant',  # Thay thế bằng host thực tế\n",
    "    'port': 6333,           # Thay thế bằng cổng thực tế nếu khác\n",
    "    # Thêm các thông tin cấu hình khác nếu cần, như API key\n",
    "}\n",
    "broadcast_qdrant_config = sc.broadcast(qdrant_config)\n",
    "\n",
    "# Tên collection trong Qdrant\n",
    "collection_name = 'user_embeddings'  # Thay thế bằng tên collection của bạn\n",
    "\n",
    "# Hàm chuyển Vector sang list\n",
    "def vector_to_list(vector):\n",
    "    return vector.toArray().tolist() if hasattr(vector, 'toArray') else vector\n",
    "\n",
    "vector_to_list_udf = udf(vector_to_list, ArrayType(FloatType()))\n",
    "\n",
    "# Tiền xử lý DataFrame\n",
    "df_preprocessed = df_final.select(\n",
    "    regexp_replace(col(\"user_id\"), \",\", \"\").cast(IntegerType()).alias(\"user_id\"),\n",
    "    \"product_id\",\n",
    "    \"score\",\n",
    "    vector_to_list_udf(col(\"user_embedding\")).alias(\"user_embedding\")\n",
    ")\n",
    "\n",
    "# Định nghĩa hàm upsert với retry logic\n",
    "def upsert_partition(partition):\n",
    "    try:\n",
    "        config = broadcast_qdrant_config.value\n",
    "        client = QdrantClient(host=config['host'], port=config['port'], timeout=30)\n",
    "        points = []\n",
    "        batch_size = 1000  # Kích thước batch\n",
    "        max_retries = 3\n",
    "        retry_delay = 5  # giây\n",
    "\n",
    "        for row in partition:\n",
    "            try:\n",
    "                point = PointStruct(\n",
    "                    id=row['user_id'],\n",
    "                    vector=row['user_embedding'],\n",
    "                    payload={\n",
    "                        \"product_id\": row['product_id'],\n",
    "                        \"score\": row['score']\n",
    "                    }\n",
    "                )\n",
    "                points.append(point)\n",
    "\n",
    "                if len(points) >= batch_size:\n",
    "                    for attempt in range(max_retries):\n",
    "                        try:\n",
    "                            client.upsert(collection_name=collection_name, points=points)\n",
    "                            logger.info(f\"Upserted {len(points)} points\")\n",
    "                            break\n",
    "                        except Exception as e:\n",
    "                            logger.error(f\"Retry {attempt + 1}/{max_retries} failed: {e}\")\n",
    "                            time.sleep(retry_delay)\n",
    "                    else:\n",
    "                        logger.error(\"All retry attempts failed for batch upsert\")\n",
    "                    points = []\n",
    "            except Exception as row_e:\n",
    "                logger.error(f\"Error processing row {row['user_id']}: {row_e}\")\n",
    "\n",
    "        # Upsert các points còn lại\n",
    "        if points:\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    client.upsert(collection_name=collection_name, points=points)\n",
    "                    logger.info(f\"Upserted final {len(points)} points\")\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Retry {attempt + 1}/{max_retries} failed: {e}\")\n",
    "                    time.sleep(retry_delay)\n",
    "            else:\n",
    "                logger.error(\"All retry attempts failed for final batch upsert\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in upsert_partition: {e}\")\n",
    "\n",
    "# Áp dụng upsert cho từng phân vùng\n",
    "df_preprocessed.rdd.foreachPartition(upsert_partition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d4565f-497c-4bce-ac18-cb080b7c00d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e4e08e-1d04-4802-aaf9-ee283f2e68cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
